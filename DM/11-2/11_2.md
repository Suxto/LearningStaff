# 11 - 2 作业

1. **什么是半监督学习**
   1. 不需要完全标注数据的类别
   2. 可以从已标注的和无标注的数据中学习：**LU学习**
   3. 可以从正类和无标注的数据中学习：**PU学习**
2. **什么是LU学习**
   1. 从已标注的和无标注的数据中学习
   2. 具体方法：
      1. 将一个基本算法迭代多次的 **EM算法**
         1. 基于两个假设：
            1. 数据是由某个**混合模型**生成的
            2. 混合分量和分类类别之间有着一一对应的关系
         2. 具体操作
            1. 先从有标注的数据中得到一个 **最初** 的分类器
            2. 循环迭代直到分类器 **稳定**
               1. **E-Step：**用分类器对 **无标签** 的数据精选分类
               2. **M-Step：**根据上面的分类在 **数据全集** 中计算出一个 **新的分类器**
         3. 两种解决第二个假设在现实中**通常不成立**的方法
            1. 给 **无标注数据** 加权：给定一个因子 $$\mu\in[0,1]$$，用于调整学习时对无标注数据标签的 **采纳程度**
            2. 寻找 **混合分量** ：将大的类别用下面的小类别替代
      2. 用不同学习器学习不同属性集的 **co-training算法**
         1. 基于两个假设
            1. 不同目标函数下类别分布 **相容** ：对大多数数据真正的分类与在 **不同属性集上学习的分类器结果相同**。
            2. 特征之间是 **条件独立** 
         2. 具体操作
            1. 从 **标记数据集** 的 $x_1$ 属性学习分类器 $f_1$
            2. 从 **标记数据集** 的 $x_2$ 属性学习分类器 $f_2$
            3. 将 **无标记数据集** 中分类器 $f_1$ 置信程度最高的 $n_1$ 个数据加入 **标记数据集**
            4. 将 **无标记数据集** 中分类器 $f_2$ 置信程度最高的 $n_2$ 个数据加入 **标记数据集**
            5. 运行直到 **无标记数据集** 为空或达到预定循环次数
         3. 最后的分类由学习到的所有分类器共同给出
      3. 自学习：先从 **标注数据集** 得到分类器，每次将**置信度最高**的分类<u>加入</u> **标注数据集**
3. **什么是PU学习**
   1. 给定一个正例集合 $P$ 和无标注集合 $U$，$U$ 中同时含有 **正类和反例**
   2. 通过两步方法建立分类器：
      1. 从无标记数据中发现一些可靠的**反例**文档组合(RN)
      2. 利用P、RN和U-RN（Q）来建立分类器，将Q中的**可靠反例**增加到RN中。